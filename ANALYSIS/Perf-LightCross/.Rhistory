# This script focuses on finding the optimal two-tool combinations
# based on vulnerability coverage, detection time, and efficiency
library(tidyverse)
library(ggplot2)
library(viridis)
library(gridExtra)
library(scales)
library(ggrepel)
# Load and preprocess data
smartbugs_raw <- read_csv("smartbugs-raw.csv")
vuln_per_file <- read_csv("vuln-per-file.csv")
vuln_mapping <- read_csv("vulnerabilities_mapping_all_tools.csv")
# Function to parse findings
parse_findings <- function(str) {
if (is.na(str) || str == "{}" || str == "") {
return(character(0))
}
str_remove_all(str, "^\\{|\\}$") %>%
str_split(",") %>%
unlist() %>%
str_trim() %>%
.[. != ""]
}
# Process vulnerability mapping
vuln_mapping_long <- vuln_mapping %>%
# Select only the columns we need (exclude "Ignore" column)
select(-Ignore) %>%
# Convert to long format
pivot_longer(
cols = c(access_control, arithmetic, denial_service, reentrancy,
unchecked_low_calls, bad_randomness, front_running,
time_manipulation, short_addresses, Other),
names_to = "vulnerability_type",
values_to = "can_detect"
) %>%
# Filter only where can_detect is "x" or similar (non-NA and non-empty)
filter(!is.na(can_detect) & can_detect != "")
# Map the vulnerability types in the mapping to match those in vulnperfile.csv
vulnerability_type_mapping <- c(
"access_control" = "ACCESS_CONTROL",
"arithmetic" = "ARITHMETIC",
"denial_service" = "DENIAL_OF_SERVICE",
"reentrancy" = "REENTRANCY",
"unchecked_low_calls" = "UNCHECKED_LL_CALLS",
"bad_randomness" = "BAD_RANDOMNESS",
"front_running" = "FRONT_RUNNING",
"time_manipulation" = "TIME_MANIPULATION",
"short_addresses" = "SHORT_ADDRESSES",
"Other" = "OTHER"
)
# Apply the mapping
vuln_mapping_long <- vuln_mapping_long %>%
mutate(vulnerability_type = vulnerability_type_mapping[vulnerability_type])
# Create a simplified lookup tool for capability detection
tool_capability_lookup <- vuln_mapping_long %>%
select(Tools, vulnerability_type) %>%
distinct()
# Map toolids in smartbugs_raw to Tools in vuln_mapping
# This might require some manual mapping if naming conventions differ
tool_name_mapping <- setNames(
c("slither", "confuzzius", "conkas", "honeybadger", "maian", "manticore", "mythril",
"osiris", "oyente", "securify", "semgrep", "sfuzz", "smartcheck", "solhint"),
unique(smartbugs_raw$toolid)
)
# Process the smartbugs dataset
smartbugs_processed <- smartbugs_raw %>%
mutate(
# Parse findings, errors, and fails
findings_list = map(findings, parse_findings),
errors_list = map(errors, parse_findings),
fails_list = map(fails, parse_findings),
# Count findings
findings_count = map_int(findings_list, length),
# Flag for issues
has_errors = !is.na(errors) & errors != "{}",
has_fails = !is.na(fails) & fails != "{}",
has_nonzero_exit = exit_code != 0,
has_timeout = map_lgl(fails_list, ~ any(grepl("TIMEOUT", ., fixed = TRUE)))
)
# Count vulnerabilities by type
vuln_counts <- vuln_per_file %>%
group_by(Vulnerability) %>%
summarize(
total_instances = sum(count_file),
file_count = n()
) %>%
arrange(desc(total_instances))
# Analyze tool performance metrics
tool_performance <- smartbugs_processed %>%
group_by(toolid) %>%
summarize(
runs = n(),
avg_duration = mean(duration, na.rm = TRUE),
median_duration = median(duration, na.rm = TRUE),
error_rate = mean(has_errors) * 100,
fail_rate = mean(has_fails) * 100,
nonzero_exit_rate = mean(has_nonzero_exit) * 100,
timeout_rate = mean(has_timeout) * 100,
avg_findings = mean(findings_count),
total_findings = sum(findings_count),
findings_per_second = avg_findings / avg_duration
) %>%
arrange(desc(findings_per_second))
# Create a function to check if a tool can detect a vulnerability type
can_tool_detect_vulnerability <- function(tool_id, vulnerability_type) {
# Convert toolid to the format used in vuln_mapping
tool_name <- tool_name_mapping[tool_id]
# Check if this tool-vulnerability pair exists in our capability lookup
pair_exists <- tool_capability_lookup %>%
filter(Tools == tool_name & vulnerability_type == vulnerability_type) %>%
nrow() > 0
return(pair_exists)
}
# Analyze theoretical detection capabilities
analyze_detection_capability <- function() {
# Create a dataframe of all tool-vulnerability combinations
all_tools <- unique(smartbugs_processed$toolid)
all_vulnerabilities <- unique(vuln_per_file$Vulnerability)
# Initialize results dataframe
results <- expand.grid(
tool = all_tools,
vulnerability = all_vulnerabilities,
stringsAsFactors = FALSE
) %>%
mutate(can_detect = FALSE)
# Fill in detection capabilities based on the mapping
for (i in 1:nrow(results)) {
tool_id <- results$tool[i]
vuln_type <- results$vulnerability[i]
results$can_detect[i] <- can_tool_detect_vulnerability(tool_id, vuln_type)
}
return(results)
}
# Get detection capabilities
theoretical_capabilities <- analyze_detection_capability()
# Function to analyze actual vulnerability detection by tool
detect_vulnerabilities <- function() {
# Define mapping between findings terms and vulnerability types
vulnerability_keywords <- list(
"REENTRANCY" = c("reentrancy", "reentrancy_eth", "reentrant"),
"UNCHECKED_LL_CALLS" = c("unchecked_low_level_calls", "low_level_calls", "unchecked_call"),
"ARITHMETIC" = c("arithmetic", "integer_overflow", "overflow", "underflow", "divide_by_zero"),
"FRONT_RUNNING" = c("front_running", "transaction_ordering_dependence"),
"ACCESS_CONTROL" = c("access_control", "weak_access_control", "arbitrary_send_eth"),
"DENIAL_OF_SERVICE" = c("denial_of_service", "dos"),
"BAD_RANDOMNESS" = c("bad_randomness", "weak_randomness"),
"TIME_MANIPULATION" = c("time_manipulation", "timestamp_dependence"),
"TIME" = c("timestamp_dependence", "block_timestamp"),
"SHORT_ADDRESSES" = c("short_addresses"),
"OTHER" = c("other", "miscellaneous", "general", "unknown")
)
# Initialize results dataframe
results <- expand.grid(
tool = unique(smartbugs_processed$toolid),
vulnerability = unique(vuln_per_file$Vulnerability),
stringsAsFactors = FALSE
) %>%
mutate(detections = 0)
# Process each tool run
for (i in 1:nrow(smartbugs_processed)) {
row <- smartbugs_processed[i, ]
tool <- row$toolid
findings <- row$findings_list[[1]]
basename <- row$basename
# Skip if no findings
if (length(findings) == 0) next
# Find relevant vulnerabilities for this file
relevant_vulns <- vuln_per_file %>%
filter(grepl(basename, Filename, fixed = TRUE) | grepl(Filename, basename, fixed = TRUE))
if (nrow(relevant_vulns) == 0) next
# Check each finding against each vulnerability type
for (finding in findings) {
for (j in 1:nrow(relevant_vulns)) {
vuln_type <- relevant_vulns$Vulnerability[j]
vuln_count <- relevant_vulns$count_file[j]
# Check if finding matches vulnerability keywords
keywords <- vulnerability_keywords[[vuln_type]]
if (length(keywords) > 0) {
if (any(sapply(keywords, function(kw) grepl(kw, finding, fixed = TRUE, ignore.case = TRUE)))) {
# Update detection count
idx <- which(results$tool == tool & results$vulnerability == vuln_type)
if (length(idx) > 0) {
results$detections[idx] <- results$detections[idx] + vuln_count
}
}
}
}
}
}
return(results)
}
# Get actual vulnerability detection results
actual_detections <- detect_vulnerabilities()
# Calculate coverage percentages
vuln_coverage <- actual_detections %>%
left_join(vuln_counts, by = c("vulnerability" = "Vulnerability")) %>%
mutate(
coverage_percent = ifelse(total_instances > 0,
detections / total_instances * 100,
0),
coverage_percent = pmin(coverage_percent, 100) # Cap at 100%
)
# Calculate theoretical coverage
tool_theoretical_coverage <- theoretical_capabilities %>%
left_join(vuln_counts, by = c("vulnerability" = "Vulnerability")) %>%
group_by(tool) %>%
summarize(
types_can_detect = sum(can_detect),
percent_types = types_can_detect / n() * 100,
total_instances_coverable = sum(total_instances * can_detect),
total_instances_all = sum(total_instances),
theoretical_coverage = total_instances_coverable / total_instances_all * 100
) %>%
arrange(desc(theoretical_coverage))
# Calculate actual coverage
tool_actual_coverage <- vuln_coverage %>%
group_by(tool) %>%
summarize(
total_detections = sum(detections),
total_vulnerabilities = sum(total_instances),
actual_coverage = total_detections / total_vulnerabilities * 100,
vulnerability_types_detected = sum(detections > 0),
types_percent = vulnerability_types_detected / n() * 100
) %>%
arrange(desc(actual_coverage))
# Compare theoretical vs. actual coverage
coverage_comparison <- tool_theoretical_coverage %>%
select(tool, theoretical_coverage, types_can_detect, percent_types) %>%
left_join(
tool_actual_coverage %>%
select(tool, actual_coverage, vulnerability_types_detected, types_percent),
by = "tool"
) %>%
mutate(
coverage_gap = theoretical_coverage - actual_coverage,
detection_efficiency = actual_coverage / theoretical_coverage * 100
) %>%
arrange(desc(actual_coverage))
# Merge with performance data
tool_analysis <- coverage_comparison %>%
left_join(tool_performance %>% select(toolid, avg_duration, findings_per_second),
by = c("tool" = "toolid"))
# Function to calculate tool combinations
analyze_tool_combinations <- function(top_n_tools = 10) {
# Get top tools by actual coverage
top_tools <- tool_analysis %>%
arrange(desc(actual_coverage)) %>%
head(top_n_tools) %>%
pull(tool)
# Generate all possible pairs
pairs <- combn(top_tools, 2, simplify = FALSE)
# Initialize results
results <- tibble(
tool1 = character(),
tool2 = character(),
combined_actual_coverage = numeric(),
combined_theoretical_coverage = numeric(),
detection_efficiency = numeric(),
actual_vuln_types = integer(),
theoretical_vuln_types = integer(),
combined_duration = numeric(),
actual_coverage_per_second = numeric(),
balance_score = numeric()
)
# Process each pair
for (pair in pairs) {
tool1 <- pair[1]
tool2 <- pair[2]
# Get theoretical capability data
tool1_theory <- theoretical_capabilities %>% filter(tool == tool1)
tool2_theory <- theoretical_capabilities %>% filter(tool == tool2)
# Calculate combined theoretical capability
combined_theory <- tool1_theory %>%
select(vulnerability, can_detect1 = can_detect) %>%
inner_join(
tool2_theory %>% select(vulnerability, can_detect2 = can_detect),
by = "vulnerability"
) %>%
mutate(combined_can_detect = can_detect1 | can_detect2) %>%
left_join(vuln_counts, by = c("vulnerability" = "Vulnerability"))
# Calculate theoretical metrics
total_theoretical_detectable <- sum(combined_theory$total_instances * combined_theory$combined_can_detect)
total_vulnerabilities <- sum(combined_theory$total_instances)
theoretical_coverage <- total_theoretical_detectable / total_vulnerabilities * 100
theoretical_vuln_types <- sum(combined_theory$combined_can_detect)
# Get actual detection data
tool1_actual <- vuln_coverage %>% filter(tool == tool1)
tool2_actual <- vuln_coverage %>% filter(tool == tool2)
# Calculate combined actual detections
combined_actual <- tool1_actual %>%
select(vulnerability, detections1 = detections, total_instances) %>%
inner_join(
tool2_actual %>% select(vulnerability, detections2 = detections),
by = "vulnerability"
) %>%
mutate(
# Take max detection between tools (capped at total)
combined_detections = pmin(pmax(detections1, detections2), total_instances)
)
# Calculate actual metrics
total_actual_detections <- sum(combined_actual$combined_detections)
actual_coverage <- total_actual_detections / total_vulnerabilities * 100
actual_vuln_types <- sum(combined_actual$combined_detections > 0)
# Get durations
duration1 <- tool_performance$avg_duration[tool_performance$toolid == tool1]
duration2 <- tool_performance$avg_duration[tool_performance$toolid == tool2]
combined_duration <- duration1 + duration2
# Calculate efficiency metrics
detection_efficiency <- actual_coverage / theoretical_coverage * 100
actual_coverage_per_second <- actual_coverage / combined_duration
balance_score <- actual_coverage * sqrt(actual_coverage_per_second)
# Add to results
results <- results %>%
add_row(
tool1 = tool1,
tool2 = tool2,
combined_actual_coverage = actual_coverage,
combined_theoretical_coverage = theoretical_coverage,
detection_efficiency = detection_efficiency,
actual_vuln_types = actual_vuln_types,
theoretical_vuln_types = theoretical_vuln_types,
combined_duration = combined_duration,
actual_coverage_per_second = actual_coverage_per_second,
balance_score = balance_score
)
}
return(results)
}
# Calculate tool combinations
tool_combinations <- analyze_tool_combinations(12)
# Get top combinations by different metrics
top_by_coverage <- tool_combinations %>%
arrange(desc(combined_actual_coverage)) %>%
head(5)
top_by_efficiency <- tool_combinations %>%
arrange(desc(actual_coverage_per_second)) %>%
head(5)
top_by_balance <- tool_combinations %>%
arrange(desc(balance_score)) %>%
head(5)
top_by_types <- tool_combinations %>%
arrange(desc(actual_vuln_types), desc(combined_actual_coverage)) %>%
head(5)
# Find best combinations for different time budgets
find_best_combinations_by_time <- function(combinations, time_budgets) {
results <- tibble()
for (budget in time_budgets) {
combinations_within_budget <- combinations %>%
filter(combined_duration <= budget) %>%
arrange(desc(balance_score))
if (nrow(combinations_within_budget) > 0) {
best <- combinations_within_budget %>%
head(1) %>%
mutate(time_budget = budget)
results <- bind_rows(results, best)
}
}
return(results)
}
# Define time budgets
time_budgets <- c(30, 60, 120, 300, 600)
# Find best combinations for each time budget
best_by_time <- find_best_combinations_by_time(tool_combinations, time_budgets)
# Create a comprehensive ranking
comprehensive_ranking <- tool_combinations %>%
mutate(
coverage_rank = min_rank(desc(combined_actual_coverage)),
efficiency_rank = min_rank(desc(actual_coverage_per_second)),
types_rank = min_rank(desc(actual_vuln_types)),
balance_rank = min_rank(desc(balance_score)),
combined_rank = (coverage_rank + efficiency_rank + types_rank + balance_rank) / 4
) %>%
arrange(combined_rank) %>%
head(10)
# ----- VISUALIZATIONS -----
# 1. Theoretical vs Actual Coverage by Tool
tool_coverage_plot <- ggplot(tool_analysis %>% filter(actual_coverage > 0) %>% head(10),
aes(x = reorder(tool, -actual_coverage))) +
geom_bar(aes(y = theoretical_coverage, fill = "Theoretical"),
stat = "identity", alpha = 0.7, width = 0.7) +
geom_bar(aes(y = actual_coverage, fill = "Actual"),
stat = "identity", alpha = 0.7, width = 0.7) +
geom_text(aes(y = actual_coverage + 3,
label = sprintf("%.1f%%", detection_efficiency)),
size = 3) +
scale_fill_manual(values = c("Theoretical" = "#1b9e77", "Actual" = "#d95f02")) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(
title = "Theoretical vs. Actual Vulnerability Coverage",
subtitle = "Labels show detection efficiency (actual/theoretical ratio)",
x = NULL,
y = "Coverage (%)",
fill = "Coverage Type"
)
# 2. Tool Performance: Time vs. Coverage Efficiency
tool_efficiency_plot <- ggplot(tool_analysis,
aes(x = avg_duration, y = actual_coverage)) +
geom_point(aes(size = vulnerability_types_detected,
color = findings_per_second), alpha = 0.8) +
geom_text_repel(
data = tool_analysis %>% filter(actual_coverage > 30 | findings_per_second > 0.1),
aes(label = tool),
size = 3, box.padding = 0.5
) +
scale_x_log10(labels = comma_format()) +
scale_color_viridis_c(option = "plasma") +
theme_minimal() +
labs(
title = "Tool Performance: Time vs. Coverage",
subtitle = "Bubble size represents vulnerability types detected, color shows findings/second",
x = "Average Duration (seconds, log scale)",
y = "Actual Coverage (%)",
size = "Vuln Types Detected",
color = "Findings/Second"
)
# 3. Combined Tool Coverage Efficiency
combo_efficiency_plot <- ggplot(tool_combinations,
aes(x = combined_duration, y = combined_actual_coverage)) +
geom_point(aes(size = actual_vuln_types,
color = detection_efficiency), alpha = 0.7) +
geom_vline(xintercept = time_budgets, linetype = "dashed", color = "gray", alpha = 0.5) +
geom_text_repel(
data = top_by_balance,
aes(label = paste(tool1, "+", tool2)),
size = 3, box.padding = 0.5
) +
scale_x_log10(labels = comma_format()) +
scale_color_viridis_c(option = "viridis") +
theme_minimal() +
labs(
title = "Tool Combinations: Coverage vs. Time",
subtitle = "Color shows detection efficiency, vertical lines indicate time budgets",
x = "Combined Duration (seconds, log scale)",
y = "Combined Coverage (%)",
size = "Vulnerability Types",
color = "Detection Efficiency (%)"
)
# 4. Coverage vs. Types Covered
coverage_types_plot <- ggplot(tool_combinations,
aes(x = actual_vuln_types, y = combined_actual_coverage)) +
geom_point(aes(size = combined_duration,
color = detection_efficiency), alpha = 0.7) +
geom_text_repel(
data = top_by_types,
aes(label = paste(tool1, "+", tool2)),
size = 3, box.padding = 0.5
) +
scale_color_viridis_c(option = "magma") +
theme_minimal() +
labs(
title = "Tool Combinations: Coverage vs. Vulnerability Types",
subtitle = "Bubble size represents combined duration",
x = "Number of Vulnerability Types Covered",
y = "Combined Coverage (%)",
size = "Combined Duration (s)",
color = "Detection Efficiency (%)"
)
# 5. Time Budget Optimization
time_budget_plot <- ggplot(best_by_time %>%
mutate(time_budget_label = paste0("≤ ", time_budget, "s")),
aes(x = reorder(time_budget_label, time_budget),
y = combined_actual_coverage)) +
geom_bar(stat = "identity", aes(fill = actual_coverage_per_second), width = 0.7) +
geom_text(aes(label = paste(tool1, "+", tool2)), y = 5, hjust = 0, angle = 90, size = 3) +
geom_text(aes(label = sprintf("%.1f%%", best_by_time$combined_actual_coverage)),
y = best_by_time$combined_actual_coverage + 2, size = 3) +
scale_fill_viridis_c(option = "plasma") +
theme_minimal() +
labs(
title = "Best Tool Combinations by Time Budget",
subtitle = "Optimal combinations for different time constraints",
x = "Time Budget",
y = "Coverage (%)",
fill = "Coverage Per Second"
)
# 6. Comprehensive Ranking Visualization
ranking_plot <- ggplot(comprehensive_ranking,
aes(x = reorder(paste(tool1, "+", tool2), -combined_rank),
y = combined_actual_coverage)) +
geom_bar(stat = "identity", aes(fill = actual_coverage_per_second), width = 0.7) +
geom_text(aes(label = sprintf("%.1f", combined_rank)),
y = comprehensive_ranking$combined_actual_coverage + 2, size = 3) +
scale_fill_viridis_c(option = "viridis") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(
title = "Top 10 Tool Combinations (Comprehensive Ranking)",
subtitle = "Lower rank score is better (combination of coverage, efficiency, and types)",
x = NULL,
y = "Combined Coverage (%)",
fill = "Coverage Per Second"
)
(tool_coverage_plot)
(tool_efficiency_plot)
(combo_efficiency_plot)
(time_budget_plot)
(coverage_types_plot)
(ranking_plot)
View(smartbugs_processed)
View(actual_detections)
View(combo_efficiency_plot)
View(comprehensive_ranking)
View(coverage_comparison)
View(coverage_types_plot)
View(final_dashboard)
View(ranking_plot)
View(smartbugs_processed)
View(smartbugs_raw)
View(smartbugs_processed)
View(time_budget_plot)
View(tool_analysis)
