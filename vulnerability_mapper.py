import pandas as pd
import re
import json
import numpy as np
import os
import glob
from typing import Dict, List, Any, Tuple, Optional, Set, Union
import matplotlib.pyplot as plt
from collections import Counter, defaultdict



class OpenScvVulnerabilityMapper:
    """
    Map smart contract vulnerabilities from multiple output CSV files
    to their corresponding classifications in openscvfull.csv.
    """

    def __init__(self, vulnerability_files: Union[List[str], str], openscv_csv_path: str):
        """
        Initialize the mapper with the paths to the vulnerability files and the OpenSCV file.

        Args:
            vulnerability_files: Path(s) to the vulnerability CSV files. Can be:
                                - A string with a single file path
                                - A list of file paths
                                - A string with a glob pattern (e.g., 'output_*.csv')
            openscv_csv_path: Path to the openscvfull.csv file
        """
        if isinstance(vulnerability_files, str):
            if '*' in vulnerability_files:
                self.vulnerability_files = glob.glob(vulnerability_files)
            else:
                self.vulnerability_files = [vulnerability_files]
        else:
            self.vulnerability_files = vulnerability_files

        self._validate_input_files()

        self.vulnerability_df = self._read_vulnerability_files()

        self.openscv_df = pd.read_csv(openscv_csv_path)

        self.openscv_df['clean_swc'] = self.openscv_df['SWC'].apply(
            lambda x: str(x) if pd.notna(x) and str(x) != '-' and str(x) != 'nan' else None
        )

        self.mapping_rules = self._create_mapping_rules()

        self.openscv_entries_cache = {}

        self.stats = {
            'total_vulnerabilities': len(self.vulnerability_df),
            'mapped_by_swc': 0,
            'mapped_by_keyword': 0,
            'unmapped': 0,
            'mapped_swc_ids': set(),
            'unmapped_vulnerabilities': [],
            'by_source_file': {}
        }

    def _validate_input_files(self) -> None:
        """
        Validate that all specified input files exist and are accessible.
        Raises an exception if any file is missing.
        """
        missing_files = [f for f in self.vulnerability_files if not os.path.exists(f)]
        if missing_files:
            raise FileNotFoundError(f"The following input files were not found: {', '.join(missing_files)}")

    def _read_vulnerability_files(self) -> pd.DataFrame:
        """
        Read and merge all vulnerability files into a single DataFrame.

        Returns:
            A DataFrame containing data from all input vulnerability files
        """
        dfs = []

        for file_path in self.vulnerability_files:
            file_name = os.path.basename(file_path)
            category = file_name.replace('output_', '').replace('.csv', '')

            df = pd.read_csv(file_path)

            # Add source file and category information
            df['source_file'] = file_name
            df['vulnerability_category'] = category
            dfs.append(df)

            # Update statistics
            # self.stats['by_source_file'][file_name] = len(df)

        if dfs:
            vuln_df = pd.concat(dfs, ignore_index=True)
            return vuln_df.drop_duplicates()
        else:
            return pd.DataFrame(columns=[
                'Tool', 'File', 'Contract', 'Vulnerability', 'Severity',
                'SWC-ID', 'Remediation', 'Description/More Info',
                'Execution time', 'Total Time', 'source_file', 'vulnerability_category'
            ])

    def _create_mapping_rules(self) -> Dict[str, Dict[str, Any]]:
        """
        Create mapping rules based on SWC-IDs and keywords.
        Also extracts keywords from the openscvfull.csv descriptions.

        Returns:
            Dictionary of mapping rules
        """
        # Base mapping rules from our analysis
        base_rules = {
            "SWC-101": {
                "categories": ["Integer Arithmetic Bugs", "arithmetic"],
                "keywords": ["integer overflow", "overflow", "underflow", "arithmetic",
                             "addition overflow", "subtraction overflow", "multiply overflow"]
            },
            "SWC-116": {
                "categories": ["Dependence on predictable environment variable", "time_manipulation"],
                "keywords": ["timestamp", "block.timestamp", "now", "block.number", "time manipulation"]
            },
            "SWC-114": {
                "categories": ["Transaction Order Dependence", "front_running"],
                "keywords": ["transaction order", "race condition", "front running"]
            },
            "SWC-110": {
                "categories": ["Exception State"],
                "keywords": ["exception", "assert", "require", "revert"]
            },
            "SWC-105": {
                "categories": ["Unprotected Ether Withdrawal"],
                "keywords": ["ether withdrawal", "unauthorized", "unprotected"]
            },
            "SWC-107": {
                "categories": ["reentrancy"],
                "keywords": ["reentrancy", "reentrant", "re-entrancy", "recursive call"]
            },
            "SWC-132": {
                "categories": [],
                "keywords": ["tautology", "contradiction", "logic"]
            },
            "SWC-108": {
                "categories": [],
                "keywords": ["naming convention", "mixedcase", "camelcase", "style"]
            },
            "SWC-103": {
                "categories": [],
                "keywords": ["floating pragma", "compiler version", "solidity version"]
            },
            "SWC-120": {
                "categories": ["bad_randomness"],
                "keywords": ["weak random", "bad randomness", "predictable random", "entropy"]
            },
            "SWC-113": {
                "categories": ["denial_of_service"],
                "keywords": ["denial of service", "dos", "gas limit", "block gas limit"]
            },
            "SWC-112": {
                "categories": ["access_control"],
                "keywords": ["access control", "authorization", "permission", "ownership"]
            },
            "SWC-104": {
                "categories": ["unchecked_low_level_calls"],
                "keywords": ["unchecked call", "low level call", "external call", "call.value"]
            },
            "SWC-115": {
                "categories": ["tx.origin"],
                "keywords": ["tx.origin", "authentication", "transaction origin"]
            }
        }

        # Add category-based mapping from file names to SWC-IDs
        category_to_swc = {
            "arithmetic": "SWC-101",
            "access_control": "SWC-112",
            "time_manipulation": "SWC-116",
            "reentrancy": "SWC-107",
            "front_running": "SWC-114",
            "denial_of_service": "SWC-113",
            "bad_randomness": "SWC-120",
            "unchecked_low_level_calls": "SWC-104"
        }

        # Enhance rules with keywords from openscvfull.csv
        for _, row in self.openscv_df.iterrows():
            swc_id = row['clean_swc']
            if not swc_id:
                continue

            if swc_id not in base_rules:
                base_rules[swc_id] = {
                    "categories": [],
                    "keywords": []
                }

            # Extract keywords from synonyms
            if pd.notna(row['Synonyms']):
                synonyms = str(row['Synonyms']).lower().split(',')
                for synonym in synonyms:
                    synonym = synonym.strip()
                    if synonym and synonym not in base_rules[swc_id]["keywords"]:
                        base_rules[swc_id]["keywords"].append(synonym)

        return base_rules

    def extract_swc_id(self, swc_id_field: str) -> Optional[str]:
        """
        Extract the SWC-ID from the field in output CSV files.

        Args:
            swc_id_field: The SWC-ID field from the CSV

        Returns:
            Cleaned SWC-ID or None if not found
        """
        if not isinstance(swc_id_field, str):
            return None

        match = re.search(r'SWC-(\d+)', swc_id_field)
        return f"SWC-{match.group(1)}" if match else None

    def map_vulnerability_by_swc(self, vulnerability_row: pd.Series) -> Optional[str]:
        """
        Map a vulnerability to an SWC-ID based on its SWC field.

        Args:
            vulnerability_row: A row from a vulnerability CSV file

        Returns:
            SWC-ID or None if not found
        """
        swc_id = self.extract_swc_id(vulnerability_row['SWC-ID'])
        if swc_id:
            self.stats['mapped_by_swc'] += 1
            self.stats['mapped_swc_ids'].add(swc_id)
            return swc_id
        return None

    def map_vulnerability_by_keyword(self, vulnerability_row: pd.Series) -> Optional[str]:
        """
        Map a vulnerability to an SWC-ID based on keywords in its description.
        Uses a scoring system to find the best match.

        Args:
            vulnerability_row: A row from a vulnerability CSV file

        Returns:
            SWC-ID or None if no good match found
        """
        vuln_desc = str(vulnerability_row['Vulnerability']).lower()

        # Check category from source file
        if 'vulnerability_category' in vulnerability_row:
            category = vulnerability_row['vulnerability_category']
            category_mapping = {
                "arithmetic": "SWC-101",
                "access_control": "SWC-112",
                "time_manipulation": "SWC-116",
                "short_addresses": "SWC-121",
                "reentrancy": "SWC-107",
                "front_running": "SWC-114",
                "denial_of_service": "SWC-113",
                "bad_randomness": "SWC-120",
                "unchecked_low_level_calls": "SWC-104"
            }

            if category in category_mapping:
                self.stats['mapped_by_keyword'] += 1
                self.stats['mapped_swc_ids'].add(category_mapping[category])
                return category_mapping[category]

        # Check for category headers (sections in the output)
        if vuln_desc.startswith("===="):
            category = vuln_desc.replace("=", "").strip().lower()
            for swc_id, rules in self.mapping_rules.items():
                if any(cat.lower() == category for cat in rules["categories"]):
                    self.stats['mapped_by_keyword'] += 1
                    self.stats['mapped_swc_ids'].add(swc_id)
                    return swc_id

        # Check for version constraint issues (very common in Solidity)
        if "version constraint" in vuln_desc and "contains known severe issues" in vuln_desc:
            self.stats['mapped_by_keyword'] += 1
            self.stats['mapped_swc_ids'].add("SWC-103")
            return "SWC-103"

        # Score-based keyword matching
        scores = defaultdict(int)
        for swc_id, rules in self.mapping_rules.items():
            # Check each keyword
            for keyword in rules["keywords"]:
                if keyword in vuln_desc:
                    # More specific (longer) keywords get higher scores
                    scores[swc_id] += len(keyword)

        # Get the best match if score is high enough
        if scores:
            best_swc_id = max(scores.items(), key=lambda x: x[1])
            if best_swc_id[1] > 5:  # Minimum score threshold
                self.stats['mapped_by_keyword'] += 1
                self.stats['mapped_swc_ids'].add(best_swc_id[0])
                return best_swc_id[0]

        # If we reach here, no good match was found
        self.stats['unmapped'] += 1
        self.stats['unmapped_vulnerabilities'].append(vuln_desc)
        return None

    def get_openscv_entries(self, swc_id: str) -> List[Dict[str, Any]]:
        """
        Get all entries from openscvfull.csv that match a given SWC-ID.
        Uses caching for performance.

        Args:
            swc_id: The SWC-ID to match

        Returns:
            List of matching entries with relevant fields
        """
        if not swc_id:
            return []

        # Use cached result if available
        if swc_id in self.openscv_entries_cache:
            return self.openscv_entries_cache[swc_id]

        matching_entries = self.openscv_df[self.openscv_df['clean_swc'] == swc_id]

        result = []
        for _, row in matching_entries.iterrows():
            result.append({
                "index": row['Index '] if 'Index ' in row else None,
                "defect_type": row['DefectType'] if 'DefectType' in row else None,
                "description": row['Desc'] if 'Desc' in row else None,
                "synonyms": row['Synonyms'] if 'Synonyms' in row else None
            })

        # Cache the result
        self.openscv_entries_cache[swc_id] = result

        return result

    def map_vulnerabilities(self) -> pd.DataFrame:
        """
        Map all vulnerabilities from the input CSV files to their corresponding
        entries in openscvfull.csv.

        Returns:
            DataFrame with mapping results
        """
        results = []

        # Reset statistics
        self.stats = {
            'total_vulnerabilities': len(self.vulnerability_df),
            'mapped_by_swc': 0,
            'mapped_by_keyword': 0,
            'unmapped': 0,
            'mapped_swc_ids': set(),
            'unmapped_vulnerabilities': [],
            'by_source_file': {f: 0 for f in self.stats['by_source_file'].keys()}
        }

        # Process each vulnerability
        for _, vuln_row in self.vulnerability_df.iterrows():
            # First try mapping by SWC-ID
            swc_id = self.map_vulnerability_by_swc(vuln_row)
            mapping_method = "SWC-ID" if swc_id else None

            # If no SWC-ID found, try mapping by keyword
            if not swc_id:
                swc_id = self.map_vulnerability_by_keyword(vuln_row)
                mapping_method = "Keyword" if swc_id else None

            # Get corresponding entries from openscvfull.csv
            openscv_entries = self.get_openscv_entries(swc_id)

            # Add to results
            result = {
                "tool": vuln_row['Tool'] if 'Tool' in vuln_row else None,
                "file": vuln_row['File'] if 'File' in vuln_row else None,
                "contract": vuln_row['Contract'] if 'Contract' in vuln_row else None,
                "vulnerability": vuln_row['Vulnerability'] if 'Vulnerability' in vuln_row else None,
                "severity": vuln_row['Severity'] if 'Severity' in vuln_row else None,
                "original_swc_id": vuln_row['SWC-ID'] if 'SWC-ID' in vuln_row else None,
                "mapped_swc_id": swc_id,
                "mapping_method": mapping_method,
                "openscv_entries": openscv_entries,
                "has_match": len(openscv_entries) > 0,
                "source_file": vuln_row['source_file'] if 'source_file' in vuln_row else None,
                "vulnerability_category": vuln_row[
                    'vulnerability_category'] if 'vulnerability_category' in vuln_row else None
            }

            results.append(result)

        # Convert to DataFrame for easier handling
        result_df = pd.DataFrame(results)

        return result_df

    def export_mapping(self, output_path: str) -> None:
        """
        Export the mapping results to a CSV file.

        Args:
            output_path: Path to save the output CSV
        """
        result_df = self.map_vulnerabilities()

        # Flatten the openscv_entries for CSV export
        flattened_results = []
        for _, row in result_df.iterrows():
            openscv_entries = row['openscv_entries']

            if not openscv_entries:
                # No matching entries found, still include the vulnerability
                flattened_results.append({
                    "tool": row['tool'],
                    "file": row['file'],
                    "contract": row['contract'],
                    "vulnerability": row['vulnerability'],
                    "severity": row['severity'],
                    "original_swc_id": row['original_swc_id'],
                    "mapped_swc_id": row['mapped_swc_id'],
                    "mapping_method": row['mapping_method'],
                    "openscv_index": None,
                    "openscv_defect_type": None,
                    "openscv_description": None,
                    "source_file": row['source_file'],
                    "vulnerability_category": row['vulnerability_category']
                })
            else:
                # Include a row for each matching entry
                for entry in openscv_entries:
                    flattened_results.append({
                        "tool": row['tool'],
                        "file": row['file'],
                        "contract": row['contract'],
                        "vulnerability": row['vulnerability'],
                        "severity": row['severity'],
                        "original_swc_id": row['original_swc_id'],
                        "mapped_swc_id": row['mapped_swc_id'],
                        "mapping_method": row['mapping_method'],
                        "openscv_index": entry['index'],
                        "openscv_defect_type": entry['defect_type'],
                        "openscv_description": entry['description'],
                        "source_file": row['source_file'],
                        "vulnerability_category": row['vulnerability_category']
                    })

        # Convert to DataFrame and export
        pd.DataFrame(flattened_results).to_csv(output_path, index=False)

    def export_json_mapping(self, output_path: str) -> None:
        """
        Export the mapping results to a JSON file with more detailed structure.

        Args:
            output_path: Path to save the output JSON
        """
        result_df = self.map_vulnerabilities()

        # Convert to list of dictionaries for JSON export
        results_list = result_df.to_dict(orient='records')

        # Write to JSON file
        with open(output_path, 'w') as f:
            json.dump(results_list, f, indent=2)

    def generate_statistics(self, output_dir: str = None) -> Dict[str, Any]:
        """
        Generate statistics about the mapping process and optionally
        create visualizations.

        Args:
            output_dir: Directory to save the visualizations (optional)

        Returns:
            Dictionary of statistics
        """
        # Ensure we have mapping results
        result_df = self.map_vulnerabilities()

        # Calculate additional statistics
        match_stats = {
            'total': len(result_df),
            'matched': result_df['has_match'].sum(),
            'unmatched': len(result_df) - result_df['has_match'].sum(),
            'match_rate': round(result_df['has_match'].mean() * 100, 2)
        }

        # Count occurrences of each SWC-ID
        swc_counts = Counter(
            result_df[result_df['mapped_swc_id'].notna()]['mapped_swc_id']
        )

        # Count defect types
        defect_types = []
        for entries in result_df['openscv_entries']:
            for entry in entries:
                if entry['defect_type']:
                    defect_types.append(entry['defect_type'])
        defect_type_counts = Counter(defect_types)

        # Count vulnerabilities by source file and category
        file_counts = Counter(result_df['source_file'])
        category_counts = Counter(result_df['vulnerability_category'])

        # Count mapping methods by category
        mapping_by_category = {}
        for category in category_counts.keys():
            category_df = result_df[result_df['vulnerability_category'] == category]
            mapping_by_category[category] = {
                'swc_id': (category_df['mapping_method'] == 'SWC-ID').sum(),
                'keyword': (category_df['mapping_method'] == 'Keyword').sum(),
                'unmapped': category_df['mapping_method'].isna().sum(),
                'total': len(category_df),
                'match_rate': round(category_df['has_match'].mean() * 100, 2)
            }

        # Compile statistics
        statistics = {
            'mapping_method': {
                'swc_id': self.stats['mapped_by_swc'],
                'keyword': self.stats['mapped_by_keyword'],
                'unmapped': self.stats['unmapped']
            },
            'match_stats': match_stats,
            'swc_counts': dict(swc_counts),
            'defect_type_counts': dict(defect_type_counts),
            'mapped_swc_ids': list(self.stats['mapped_swc_ids']),
            'file_counts': dict(file_counts),
            'category_counts': dict(category_counts),
            'mapping_by_category': mapping_by_category,
            'unmapped_sample': self.stats['unmapped_vulnerabilities'][:10] if self.stats[
                'unmapped_vulnerabilities'] else []
        }

        # Generate visualizations if output_dir is provided
        if output_dir:
            self._generate_visualizations(statistics, output_dir)

        return statistics

    def _generate_visualizations(self, statistics: Dict[str, Any], output_dir: str) -> None:
        """
        Generate visualizations of the mapping statistics.

        Args:
            statistics: Dictionary of statistics
            output_dir: Directory to save the visualizations
        """
        # Create the output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # 1. Pie chart of mapping methods
        plt.figure(figsize=(10, 6))
        labels = ['Mapped by SWC-ID', 'Mapped by Keyword', 'Unmapped']
        sizes = [
            statistics['mapping_method']['swc_id'],
            statistics['mapping_method']['keyword'],
            statistics['mapping_method']['unmapped']
        ]
        plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
        plt.axis('equal')
        plt.title('Vulnerability Mapping Methods')
        plt.savefig(os.path.join(output_dir, 'mapping_methods_pie.png'))
        plt.close()

        # 2. Bar chart of SWC-ID counts
        plt.figure(figsize=(12, 8))
        swc_ids = list(statistics['swc_counts'].keys())
        counts = list(statistics['swc_counts'].values())

        # Sort by count
        swc_counts_sorted = sorted(zip(swc_ids, counts), key=lambda x: x[1], reverse=True)
        swc_ids = [x[0] for x in swc_counts_sorted]
        counts = [x[1] for x in swc_counts_sorted]

        plt.bar(swc_ids, counts)
        plt.xlabel('SWC-ID')
        plt.ylabel('Count')
        plt.title('Vulnerability Distribution by SWC-ID')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'swc_id_distribution.png'))
        plt.close()

        # 3. Bar chart of defect types
        plt.figure(figsize=(12, 8))
        defect_types = list(statistics['defect_type_counts'].keys())
        defect_counts = list(statistics['defect_type_counts'].values())

        # Sort by count
        defect_counts_sorted = sorted(zip(defect_types, defect_counts), key=lambda x: x[1], reverse=True)
        defect_types = [x[0] for x in defect_counts_sorted]
        defect_counts = [x[1] for x in defect_counts_sorted]

        plt.bar(defect_types, defect_counts)
        plt.xlabel('Defect Type')
        plt.ylabel('Count')
        plt.title('Defect Type Distribution')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'defect_type_distribution.png'))
        plt.close()

        # 4. Bar chart of vulnerability categories
        plt.figure(figsize=(12, 8))
        categories = list(statistics['category_counts'].keys())
        category_counts = list(statistics['category_counts'].values())

        # Sort by count
        category_counts_sorted = sorted(zip(categories, category_counts), key=lambda x: x[1], reverse=True)
        categories = [x[0] for x in category_counts_sorted]
        category_counts = [x[1] for x in category_counts_sorted]

        plt.bar(categories, category_counts)
        plt.xlabel('Vulnerability Category')
        plt.ylabel('Count')
        plt.title('Vulnerability Distribution by Category')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'category_distribution.png'))
        plt.close()

        # 5. Stacked bar chart of mapping methods by category
        plt.figure(figsize=(14, 8))
        categories = list(statistics['mapping_by_category'].keys())

        # Sort categories by total count
        categories_sorted = sorted(
            categories,
            key=lambda x: statistics['mapping_by_category'][x]['total'],
            reverse=True
        )

        swc_id_counts = [statistics['mapping_by_category'][cat]['swc_id'] for cat in categories_sorted]
        keyword_counts = [statistics['mapping_by_category'][cat]['keyword'] for cat in categories_sorted]
        unmapped_counts = [statistics['mapping_by_category'][cat]['unmapped'] for cat in categories_sorted]

        bar_width = 0.8
        indices = np.arange(len(categories_sorted))

        plt.bar(indices, swc_id_counts, bar_width, label='SWC-ID')
        plt.bar(indices, keyword_counts, bar_width, bottom=swc_id_counts, label='Keyword')
        plt.bar(indices, unmapped_counts, bar_width, bottom=[i + j for i, j in zip(swc_id_counts, keyword_counts)],
                label='Unmapped')

        plt.xlabel('Vulnerability Category')
        plt.ylabel('Count')
        plt.title('Mapping Methods by Vulnerability Category')
        plt.xticks(indices, categories_sorted, rotation=45, ha='right')
        plt.legend()
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'mapping_by_category.png'))
        plt.close()