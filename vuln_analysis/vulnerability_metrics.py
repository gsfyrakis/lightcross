import csv
import os
import re
from collections import defaultdict
from os.path import basename


def slither_detector_to_swc(detector_name):
    """
    Map a Slither detector name to its corresponding SWC ID.

    Args:
        detector_name (str): The name of the Slither detector

    Returns:
        str: The SWC ID if found, or None if no mapping exists
    """
    # Mapping of Slither detector names to SWC IDs
    mapping = {
        "arbitrary-send-erc20": "105",
        "encode-packed-collision": "133",
        "rtlo": "130",
        "shadowing-state": "119",
        "suicidal": "106",
        "uninitialized-state": "109",
        "uninitialized-storage": "109",
        "arbitrary-send-erc20-permit": "105",
        "arbitrary-send-eth": "105",
        "controlled-delegatecall": "106",
        "incorrect-exp": "129",
        "reentrancy-eth": "107",
        "unchecked-transfer": "104",
        "weak-prng": "120",
        "locked-ether": "132",
        "shadowing-abstract": "119",
        "reentrancy-no-eth": "107",
        "tx-origin": "115",
        "unchecked-lowlevel": "104",
        "unchecked-send": "104",
        "uninitialized-local": "109",
        "unused-return": "135",
        "shadowing-local": "119",
        "calls-loop": "113",
        "incorrect-unary": "129",
        "missing-zero-check": "105",
        "reentrancy-benign": "107",
        "reentrancy-events": "107",
        "return-bomb": "126",
        "timestamp": "116",
        "assert-state-change": "110",
        "deprecated-standards": "111",
        "low-level-calls": "104",
        "pragma": "103",
        "redundant-statements": "135",
        "solc-version": "102",
        "unimplemented-functions": "135",
        "unused-state": "131",
        "costly-loop": "128",
        "dead-code": "135",
        "reentrancy-unlimited-gas": "107"
    }

    # Convert detector name to lowercase for case-insensitive matching
    detector_name_lower = detector_name.lower()

    return mapping.get(detector_name_lower)

def extract_swc_id(swc_id_string):
    """Extract the numeric part of SWC-ID from a string."""
    if not swc_id_string:
        return None
    
    # Try to extract a numeric ID
    match = re.search(r'SWC-(\d+)', swc_id_string)
    if match and match.group(1):
        return match.group(1)
    return None


def extract_filename(file_path):
    """Extract the filename from a file path."""
    if not file_path:
        return None
    base =  os.path.basename(file_path)
    filename = re.split(r'#', base)[0]
    return filename

def determine_dasp_category(swc_id, vulnerability):
    """Determine the DASP category based on SWC-ID or vulnerability description."""
    # SWC-ID to DASP category mapping
    swc_to_dasp = {
        # Access Control related
        "105": "Access Control",  # Unprotected Ether Withdrawal
        "106": "Access Control",  # Unprotected SELFDESTRUCT Instruction
        "112": "Access Control",  # Delegatecall to Untrusted Callee
        "115": "Access Control",  # Authorization through tx.origin
        "118": "Access Control",  # Incorrect Constructor Name
        "124": "Access Control",  # Write to Arbitrary Storage Location
        "132": "Access Control",  # Unexpected Ether Balance
        
        # Arithmetic Issues
        "101": "Arithmetic Issues",  # Integer Overflow and Underflow
        "128": "Arithmetic Issues",  # DoS With Block Gas Limit
        
        # Bad Randomness
        "120": "Bad Randomness",  # Weak Sources of Randomness from Chain Attributes
        "136": "Bad Randomness",  # Unencrypted Private Data On-Chain
        
        # Denial of Service
        "128": "Denial of Service",  # DoS With Block Gas Limit
        "113": "Denial of Service",  # DoS with Failed Call
        
        # Front-Running
        "114": "Front-Running",  # Transaction Order Dependence
        
        # Reentrancy
        "107": "Reentrancy",  # Reentrancy
        
        # Time Manipulation
        "116": "Time Manipulation",  # Block values as a proxy for time
        "133": "Time Manipulation",  # Hash Collisions With Multiple Variable Length Arguments
        
        # Unchecked Return Values
        "104": "Unchecked Return Values",  # Unchecked Call Return Value
        "113": "Unchecked Return Values",  # DoS with Failed Call (can also be categorized as Unchecked Return)
    }
    
    # Vulnerability keyword to DASP category mapping
    vul_keywords_to_dasp = {
        "reentrancy": "Reentrancy",
        "reentrant": "Reentrancy",
        "external call": "Reentrancy",
        
        "overflow": "Arithmetic Issues",
        "underflow": "Arithmetic Issues",
        "integer arithmetic": "Arithmetic Issues",
        "arithmetic": "Arithmetic Issues",
        "arbitrary-send-eth"  :  "Access Control",
        "access control": "Access Control",
        "authorization": "Access Control",
        "permissions": "Access Control",
        "tx.origin": "Access Control",
        "tx-origin": "Access Control",
        "constructor name": "Access Control",
        "arbitrary write": "Access Control",
        
        "random": "Bad Randomness",
        "randomness": "Bad Randomness",
        
        "dos": "Denial of Service",
        "denial of service": "Denial of Service",
        "gas limit": "Denial of Service",
        
        "front run": "Front-Running",
        "transaction order": "Front-Running",
        "race condition": "Front-Running",
        
        "timestamp": "Time Manipulation",
        "block value": "Time Manipulation",
        "time": "Time Manipulation",
        
        "unchecked": "Unchecked Return Values",
        "return value": "Unchecked Return Values",
        "low level call": "Unchecked Return Values",
        "send": "Unchecked Return Values",
        "call": "Unchecked Return Values",
        
        "short address": "Short Address/Parameter Attack",
        "parameter": "Short Address/Parameter Attack"
    }
    
    # First try to map using SWC-ID
    if swc_id and swc_id in swc_to_dasp:
        return swc_to_dasp[swc_id]
    
    # If that fails, try to map using vulnerability keywords
    if vulnerability:
        lower_vulnerability = vulnerability.lower()
        
        for keyword, category in vul_keywords_to_dasp.items():
            if keyword in lower_vulnerability:
                return category
    
    # Default to "Unknown Unknowns" if no mapping is found
    return "Unknown Unknowns"


def calculate_vulnerability_metrics(ground_truth_file, output_files):
    """
    Calculate vulnerability metrics based on ground truth and tool outputs.
    
    Args:
        ground_truth_file: Path to the ground truth CSV file (sbvulnerabilitiesdasp.csv)
        output_files: List of paths to the output CSV files
        
    Returns:
        Dictionary containing the calculated metrics
    """
    # Load ground truth data
    path_to_dasp = {}
    path_to_category = {}
    ground_truth_files = set()
    
    with open(ground_truth_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if 'path' in row and row['path']:
                path = row['path']
                filename = extract_filename(path)
                
                # Store both the full path and just the filename
                path_to_dasp[path] = row['dasp']
                path_to_category[path] = row['category']
                ground_truth_files.add(path)
                
                # Also store by just the filename
                if filename:
                    path_to_dasp[filename] = row['dasp']
                    path_to_category[filename] = row['category']
                    ground_truth_files.add(filename)
    
    # Process all detected vulnerabilities
    all_detected_vulnerabilities = []
    
    for output_file in output_files:
        with open(output_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('File') and (row.get('Vulnerability') or row.get('SWC-ID')):
                    swc_id = extract_swc_id(row.get('SWC-ID', ''))
                    dasp_category = determine_dasp_category(swc_id, row.get('Vulnerability', ''))
                    
                    all_detected_vulnerabilities.append({
                        'file': row['File'],
                        'filename': extract_filename(row['File']),
                        'swc_id': swc_id,
                        'vulnerability': row.get('Vulnerability', ''),
                        'dasp_category': dasp_category
                    })
    
    # Calculate metrics
    true_positives = 0
    false_positives = 0
    processed_files = set()
    
    # Calculate TP and FP
    for detected in all_detected_vulnerabilities:
        file_path = detected['file']
        filename = detected['filename']
        
        # Try to find the ground truth for this file
        ground_truth_dasp = path_to_dasp.get(file_path) or path_to_dasp.get(filename)
        
        if ground_truth_dasp:
            # The file exists in ground truth, check if the category matches
            if ground_truth_dasp == detected['dasp_category']:
                true_positives += 1
            else:
                false_positives += 1
            
            # Mark this file as processed
            processed_files.add(file_path)
            processed_files.add(filename)
        else:
            # The file doesn't exist in ground truth, so it's a false positive
            false_positives += 1
    
    # Calculate FN (files in ground truth but not detected)
    false_negatives = 0
    for file in ground_truth_files:
        if file not in processed_files:
            false_negatives += 1
    
    # Calculate overall metrics
    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    metrics = {
        'overall': {
            'true_positives': true_positives,
            'false_positives': false_positives,
            'false_negatives': false_negatives,
            'recall': recall,
            'precision': precision,
            'f1_score': f1_score
        },
        'per_category': {}
    }
    
    # Calculate metrics per DASP category
    dasp_categories = set(path_to_dasp.values())
    
    for category in dasp_categories:
        # Count ground truth files for this category
        category_ground_truth_files = set()
        for path, dasp in path_to_dasp.items():
            if dasp == category:
                category_ground_truth_files.add(path)
        
        # Count TP, FP, FN for this category
        category_tp = 0
        category_fp = 0
        processed_category_files = set()
        
        # Calculate TP and FP
        for detected in all_detected_vulnerabilities:
            if detected['dasp_category'] == category:
                file_path = detected['file']
                filename = detected['filename']
                
                # Try to find the ground truth for this file
                ground_truth_dasp = path_to_dasp.get(file_path) or path_to_dasp.get(filename)
                
                if ground_truth_dasp == category:
                    category_tp += 1
                    processed_category_files.add(file_path)
                    processed_category_files.add(filename)
                else:
                    category_fp += 1
        
        # Calculate FN
        category_fn = 0
        for file in category_ground_truth_files:
            if file not in processed_category_files:
                category_fn += 1
        
        # Calculate metrics
        cat_recall = category_tp / (category_tp + category_fn) if (category_tp + category_fn) > 0 else 0
        cat_precision = category_tp / (category_tp + category_fp) if (category_tp + category_fp) > 0 else 0
        cat_f1 = 2 * (cat_precision * cat_recall) / (cat_precision + cat_recall) if (cat_precision + cat_recall) > 0 else 0
        
        metrics['per_category'][category] = {
            'ground_truth_files': len(category_ground_truth_files),
            'true_positives': category_tp,
            'false_positives': category_fp,
            'false_negatives': category_fn,
            'recall': cat_recall,
            'precision': cat_precision,
            'f1_score': cat_f1
        }
    
    return metrics


def main():
    """Main function to run the vulnerability metrics calculation."""
    ground_truth_file = 'sbvulnerabilitiesdasp.csv'
    
    output_files = [
        'output_access_control.csv',
        'output_arithmetic.csv',
        'output_bad_randomness.csv',
        'output_denial_of_service.csv',
        'output_front_running.csv',
        'output_other.csv',
        'output_reentrancy.csv',
        'output_short_addresses.csv',
        'output_time_manipulation.csv',
        'output_unchecked_low_level_calls.csv'
    ]
    
    metrics = calculate_vulnerability_metrics(ground_truth_file, output_files)
    
    # Print overall metrics
    print("\nOverall Metrics:")
    print(f"True Positives: {metrics['overall']['true_positives']}")
    print(f"False Positives: {metrics['overall']['false_positives']}")
    print(f"False Negatives: {metrics['overall']['false_negatives']}")
    print(f"Recall: {metrics['overall']['recall']:.4f}")
    print(f"Precision: {metrics['overall']['precision']:.4f}")
    print(f"F1 Score: {metrics['overall']['f1_score']:.4f}")
    
    # Print metrics per category
    print("\nMetrics per DASP category:")
    for category, cat_metrics in metrics['per_category'].items():
        print(f"\n{category}:")
        print(f"  Ground Truth Files: {cat_metrics['ground_truth_files']}")
        print(f"  True Positives: {cat_metrics['true_positives']}")
        print(f"  False Positives: {cat_metrics['false_positives']}")
        print(f"  False Negatives: {cat_metrics['false_negatives']}")
        print(f"  Recall: {cat_metrics['recall']:.4f}")
        print(f"  Precision: {cat_metrics['precision']:.4f}")
        print(f"  F1 Score: {cat_metrics['f1_score']:.4f}")
    
    # Create a visualization of the results
    print("\nSaving results to vulnerability_metrics.csv")
    
    # Save results to CSV
    with open('vulnerability_metrics.csv', 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Category', 'TP', 'FP', 'FN', 'Recall', 'Precision', 'F1 Score'])
        
        # Overall metrics
        writer.writerow([
            'Overall',
            metrics['overall']['true_positives'],
            metrics['overall']['false_positives'],
            metrics['overall']['false_negatives'],
            f"{metrics['overall']['recall']:.4f}",
            f"{metrics['overall']['precision']:.4f}",
            f"{metrics['overall']['f1_score']:.4f}"
        ])
        
        # Per category metrics
        for category, cat_metrics in metrics['per_category'].items():
            writer.writerow([
                category,
                cat_metrics['true_positives'],
                cat_metrics['false_positives'],
                cat_metrics['false_negatives'],
                f"{cat_metrics['recall']:.4f}",
                f"{cat_metrics['precision']:.4f}",
                f"{cat_metrics['f1_score']:.4f}"
            ])


if __name__ == "__main__":
    main()
    